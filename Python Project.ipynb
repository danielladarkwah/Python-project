{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7649596-6c63-4cde-a269-6ce02eb0421b",
   "metadata": {},
   "source": [
    "### Session 3 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7cba391-28ca-488b-b11c-c1519d4f9baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pathlib import Path\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "datapath = Path('data')\n",
    "\n",
    "quakes = pd.read_csv(datapath / Path('earthquake.csv'))\n",
    "faang = pd.read_csv(datapath / Path('faang.csv'), index_col='date', parse_dates=True)\n",
    "covid_parsed = pd.read_pickle(datapath / Path('covid_parsed.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5024604",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "- Read in the data in the covid.csv file\n",
    "- Create a date column by parsing the dateRep column into a datetime\n",
    "- Set the date column as the index\n",
    "- Use the replace() method to update all occurrences of United_States_of_America and United Kingdom to USA and UK, respectively\n",
    "- Sort the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69ddfb69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateRep</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>countriesAndTerritories</th>\n",
       "      <th>geoId</th>\n",
       "      <th>countryterritoryCode</th>\n",
       "      <th>popData2019</th>\n",
       "      <th>continentExp</th>\n",
       "      <th>Cumulative_number_for_14_days_of_COVID-19_cases_per_100000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19/09/2020</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.616645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/09/2020</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.535155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/09/2020</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.653446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/09/2020</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.708649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15/09/2020</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.627159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43713</th>\n",
       "      <td>25/03/2020</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43714</th>\n",
       "      <td>24/03/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43715</th>\n",
       "      <td>23/03/2020</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43716</th>\n",
       "      <td>22/03/2020</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43717</th>\n",
       "      <td>21/03/2020</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43718 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dateRep  day  month  year  cases  deaths countriesAndTerritories  \\\n",
       "0      19/09/2020   19      9  2020     47       1             Afghanistan   \n",
       "1      18/09/2020   18      9  2020      0       0             Afghanistan   \n",
       "2      17/09/2020   17      9  2020     17       0             Afghanistan   \n",
       "3      16/09/2020   16      9  2020     40      10             Afghanistan   \n",
       "4      15/09/2020   15      9  2020     99       6             Afghanistan   \n",
       "...           ...  ...    ...   ...    ...     ...                     ...   \n",
       "43713  25/03/2020   25      3  2020      0       0                Zimbabwe   \n",
       "43714  24/03/2020   24      3  2020      0       1                Zimbabwe   \n",
       "43715  23/03/2020   23      3  2020      0       0                Zimbabwe   \n",
       "43716  22/03/2020   22      3  2020      1       0                Zimbabwe   \n",
       "43717  21/03/2020   21      3  2020      1       0                Zimbabwe   \n",
       "\n",
       "      geoId countryterritoryCode  popData2019 continentExp  \\\n",
       "0        AF                  AFG   38041757.0         Asia   \n",
       "1        AF                  AFG   38041757.0         Asia   \n",
       "2        AF                  AFG   38041757.0         Asia   \n",
       "3        AF                  AFG   38041757.0         Asia   \n",
       "4        AF                  AFG   38041757.0         Asia   \n",
       "...     ...                  ...          ...          ...   \n",
       "43713    ZW                  ZWE   14645473.0       Africa   \n",
       "43714    ZW                  ZWE   14645473.0       Africa   \n",
       "43715    ZW                  ZWE   14645473.0       Africa   \n",
       "43716    ZW                  ZWE   14645473.0       Africa   \n",
       "43717    ZW                  ZWE   14645473.0       Africa   \n",
       "\n",
       "       Cumulative_number_for_14_days_of_COVID-19_cases_per_100000  \n",
       "0                                               1.616645           \n",
       "1                                               1.535155           \n",
       "2                                               1.653446           \n",
       "3                                               1.708649           \n",
       "4                                               1.627159           \n",
       "...                                                  ...           \n",
       "43713                                                NaN           \n",
       "43714                                                NaN           \n",
       "43715                                                NaN           \n",
       "43716                                                NaN           \n",
       "43717                                                NaN           \n",
       "\n",
       "[43718 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data in the covid.csv file\n",
    "covid = pd.read_csv(datapath / Path('covid.csv'))\n",
    "\n",
    "# Print the dataframe to view the data\n",
    "covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f3cfbf0-df40-4ca7-9469-6f4fef078e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateRep</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>countriesAndTerritories</th>\n",
       "      <th>geoId</th>\n",
       "      <th>countryterritoryCode</th>\n",
       "      <th>popData2019</th>\n",
       "      <th>continentExp</th>\n",
       "      <th>Cumulative_number_for_14_days_of_COVID-19_cases_per_100000</th>\n",
       "      <th>parsed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19/09/2020</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.616645</td>\n",
       "      <td>2020-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/09/2020</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.535155</td>\n",
       "      <td>2020-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/09/2020</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.653446</td>\n",
       "      <td>2020-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/09/2020</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.708649</td>\n",
       "      <td>2020-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15/09/2020</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>38041757.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.627159</td>\n",
       "      <td>2020-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43713</th>\n",
       "      <td>25/03/2020</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43714</th>\n",
       "      <td>24/03/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43715</th>\n",
       "      <td>23/03/2020</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43716</th>\n",
       "      <td>22/03/2020</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43717</th>\n",
       "      <td>21/03/2020</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>14645473.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43718 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dateRep  day  month  year  cases  deaths countriesAndTerritories  \\\n",
       "0      19/09/2020   19      9  2020     47       1             Afghanistan   \n",
       "1      18/09/2020   18      9  2020      0       0             Afghanistan   \n",
       "2      17/09/2020   17      9  2020     17       0             Afghanistan   \n",
       "3      16/09/2020   16      9  2020     40      10             Afghanistan   \n",
       "4      15/09/2020   15      9  2020     99       6             Afghanistan   \n",
       "...           ...  ...    ...   ...    ...     ...                     ...   \n",
       "43713  25/03/2020   25      3  2020      0       0                Zimbabwe   \n",
       "43714  24/03/2020   24      3  2020      0       1                Zimbabwe   \n",
       "43715  23/03/2020   23      3  2020      0       0                Zimbabwe   \n",
       "43716  22/03/2020   22      3  2020      1       0                Zimbabwe   \n",
       "43717  21/03/2020   21      3  2020      1       0                Zimbabwe   \n",
       "\n",
       "      geoId countryterritoryCode  popData2019 continentExp  \\\n",
       "0        AF                  AFG   38041757.0         Asia   \n",
       "1        AF                  AFG   38041757.0         Asia   \n",
       "2        AF                  AFG   38041757.0         Asia   \n",
       "3        AF                  AFG   38041757.0         Asia   \n",
       "4        AF                  AFG   38041757.0         Asia   \n",
       "...     ...                  ...          ...          ...   \n",
       "43713    ZW                  ZWE   14645473.0       Africa   \n",
       "43714    ZW                  ZWE   14645473.0       Africa   \n",
       "43715    ZW                  ZWE   14645473.0       Africa   \n",
       "43716    ZW                  ZWE   14645473.0       Africa   \n",
       "43717    ZW                  ZWE   14645473.0       Africa   \n",
       "\n",
       "       Cumulative_number_for_14_days_of_COVID-19_cases_per_100000 parsed_date  \n",
       "0                                               1.616645           2020-09-19  \n",
       "1                                               1.535155           2020-09-18  \n",
       "2                                               1.653446           2020-09-17  \n",
       "3                                               1.708649           2020-09-16  \n",
       "4                                               1.627159           2020-09-15  \n",
       "...                                                  ...                  ...  \n",
       "43713                                                NaN           2020-03-25  \n",
       "43714                                                NaN           2020-03-24  \n",
       "43715                                                NaN           2020-03-23  \n",
       "43716                                                NaN           2020-03-22  \n",
       "43717                                                NaN           2020-03-21  \n",
       "\n",
       "[43718 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a date column by parsing the dateRep column into a datetime\n",
    "\n",
    "# Convert 'dateRep' column to datetime format\n",
    "covid['parsed_date'] = pd.to_datetime(covid['dateRep'], format='%d/%m/%Y')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dd36c31-e305-495f-96a1-e9594d9bd4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                dateRep  day  month  year  cases  deaths  \\\n",
      "parsed_date                                                \n",
      "2020-09-19   19/09/2020   19      9  2020     47       1   \n",
      "2020-09-18   18/09/2020   18      9  2020      0       0   \n",
      "2020-09-17   17/09/2020   17      9  2020     17       0   \n",
      "2020-09-16   16/09/2020   16      9  2020     40      10   \n",
      "2020-09-15   15/09/2020   15      9  2020     99       6   \n",
      "\n",
      "            countriesAndTerritories geoId countryterritoryCode  popData2019  \\\n",
      "parsed_date                                                                   \n",
      "2020-09-19              Afghanistan    AF                  AFG   38041757.0   \n",
      "2020-09-18              Afghanistan    AF                  AFG   38041757.0   \n",
      "2020-09-17              Afghanistan    AF                  AFG   38041757.0   \n",
      "2020-09-16              Afghanistan    AF                  AFG   38041757.0   \n",
      "2020-09-15              Afghanistan    AF                  AFG   38041757.0   \n",
      "\n",
      "            continentExp  \\\n",
      "parsed_date                \n",
      "2020-09-19          Asia   \n",
      "2020-09-18          Asia   \n",
      "2020-09-17          Asia   \n",
      "2020-09-16          Asia   \n",
      "2020-09-15          Asia   \n",
      "\n",
      "             Cumulative_number_for_14_days_of_COVID-19_cases_per_100000  \n",
      "parsed_date                                                              \n",
      "2020-09-19                                            1.616645           \n",
      "2020-09-18                                            1.535155           \n",
      "2020-09-17                                            1.653446           \n",
      "2020-09-16                                            1.708649           \n",
      "2020-09-15                                            1.627159           \n"
     ]
    }
   ],
   "source": [
    "# Set the date column as the index\n",
    "date_column_name = 'parsed_date'\n",
    "\n",
    "# Check if the column exists in the DataFrame\n",
    "if date_column_name in covid.columns:\n",
    "    covid.set_index(date_column_name, inplace=True)\n",
    "    print(covid.head())\n",
    "else:\n",
    "    print(f\"Column '{date_column_name}' not found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b53aea0-9b62-4bbd-a916-a4d9e0b725d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateRep</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>countriesAndTerritories</th>\n",
       "      <th>geoId</th>\n",
       "      <th>countryterritoryCode</th>\n",
       "      <th>popData2019</th>\n",
       "      <th>continentExp</th>\n",
       "      <th>Cumulative_number_for_14_days_of_COVID-19_cases_per_100000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parsed_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-19</th>\n",
       "      <td>19/09/2020</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>4322</td>\n",
       "      <td>27</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>65.396682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-11</th>\n",
       "      <td>11/05/2020</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>2157</td>\n",
       "      <td>217</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>81.247331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-18</th>\n",
       "      <td>18/09/2020</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>3395</td>\n",
       "      <td>21</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>61.822634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-17</th>\n",
       "      <td>17/09/2020</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>3991</td>\n",
       "      <td>20</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>59.331903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>16/09/2020</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>3103</td>\n",
       "      <td>27</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>55.606310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-15</th>\n",
       "      <td>15/09/2020</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>2621</td>\n",
       "      <td>9</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>52.893515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-14</th>\n",
       "      <td>14/09/2020</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>3330</td>\n",
       "      <td>5</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>51.070480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-13</th>\n",
       "      <td>13/09/2020</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>3497</td>\n",
       "      <td>9</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>48.647269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12</th>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>3539</td>\n",
       "      <td>6</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>45.062718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-11</th>\n",
       "      <td>11/09/2020</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>2919</td>\n",
       "      <td>14</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>GBR</td>\n",
       "      <td>66647112.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>41.667222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dateRep  day  month  year  cases  deaths  \\\n",
       "parsed_date                                                \n",
       "2020-09-19   19/09/2020   19      9  2020   4322      27   \n",
       "2020-05-11   11/05/2020   11      5  2020   2157     217   \n",
       "2020-09-18   18/09/2020   18      9  2020   3395      21   \n",
       "2020-09-17   17/09/2020   17      9  2020   3991      20   \n",
       "2020-09-16   16/09/2020   16      9  2020   3103      27   \n",
       "2020-09-15   15/09/2020   15      9  2020   2621       9   \n",
       "2020-09-14   14/09/2020   14      9  2020   3330       5   \n",
       "2020-09-13   13/09/2020   13      9  2020   3497       9   \n",
       "2020-09-12   12/09/2020   12      9  2020   3539       6   \n",
       "2020-09-11   11/09/2020   11      9  2020   2919      14   \n",
       "\n",
       "            countriesAndTerritories geoId countryterritoryCode  popData2019  \\\n",
       "parsed_date                                                                   \n",
       "2020-09-19                       UK    UK                  GBR   66647112.0   \n",
       "2020-05-11                       UK    UK                  GBR   66647112.0   \n",
       "2020-09-18                       UK    UK                  GBR   66647112.0   \n",
       "2020-09-17                       UK    UK                  GBR   66647112.0   \n",
       "2020-09-16                       UK    UK                  GBR   66647112.0   \n",
       "2020-09-15                       UK    UK                  GBR   66647112.0   \n",
       "2020-09-14                       UK    UK                  GBR   66647112.0   \n",
       "2020-09-13                       UK    UK                  GBR   66647112.0   \n",
       "2020-09-12                       UK    UK                  GBR   66647112.0   \n",
       "2020-09-11                       UK    UK                  GBR   66647112.0   \n",
       "\n",
       "            continentExp  \\\n",
       "parsed_date                \n",
       "2020-09-19        Europe   \n",
       "2020-05-11        Europe   \n",
       "2020-09-18        Europe   \n",
       "2020-09-17        Europe   \n",
       "2020-09-16        Europe   \n",
       "2020-09-15        Europe   \n",
       "2020-09-14        Europe   \n",
       "2020-09-13        Europe   \n",
       "2020-09-12        Europe   \n",
       "2020-09-11        Europe   \n",
       "\n",
       "             Cumulative_number_for_14_days_of_COVID-19_cases_per_100000  \n",
       "parsed_date                                                              \n",
       "2020-09-19                                           65.396682           \n",
       "2020-05-11                                           81.247331           \n",
       "2020-09-18                                           61.822634           \n",
       "2020-09-17                                           59.331903           \n",
       "2020-09-16                                           55.606310           \n",
       "2020-09-15                                           52.893515           \n",
       "2020-09-14                                           51.070480           \n",
       "2020-09-13                                           48.647269           \n",
       "2020-09-12                                           45.062718           \n",
       "2020-09-11                                           41.667222           "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update all occurrences of United_States_of_America and United_Kingdom to USA and UK respectively\n",
    "covid['countriesAndTerritories'] = covid['countriesAndTerritories'].replace('United_States_of_America', 'USA')\n",
    "covid['countriesAndTerritories'] = covid['countriesAndTerritories'].replace('United_Kingdom', 'UK')\n",
    "\n",
    "# Define custom sorting order\n",
    "custom_order = ['UK', 'USA']\n",
    "\n",
    "# Sort the index based on the custom sorting order\n",
    "covid.sort_values(by='countriesAndTerritories', key=lambda x: x.map({k: i for i, k in enumerate(custom_order)}), inplace=True)\n",
    "covid.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "288bc31f-5514-4b7b-974f-5d02780a9681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateRep</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>countriesAndTerritories</th>\n",
       "      <th>geoId</th>\n",
       "      <th>countryterritoryCode</th>\n",
       "      <th>popData2019</th>\n",
       "      <th>continentExp</th>\n",
       "      <th>Cumulative_number_for_14_days_of_COVID-19_cases_per_100000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parsed_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>31/12/2019</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-16</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>67717</td>\n",
       "      <td>953</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>247.006277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>13/05/2020</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>22048</td>\n",
       "      <td>1703</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>108.605014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-17</th>\n",
       "      <td>17/06/2020</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>23705</td>\n",
       "      <td>836</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>92.963420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>18/06/2020</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>25559</td>\n",
       "      <td>754</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>94.744223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>19/06/2020</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>27762</td>\n",
       "      <td>717</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>96.756592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-20</th>\n",
       "      <td>20/06/2020</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>29909</td>\n",
       "      <td>678</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>98.194302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-21</th>\n",
       "      <td>21/06/2020</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>34158</td>\n",
       "      <td>607</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>101.821246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22</th>\n",
       "      <td>22/06/2020</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>25793</td>\n",
       "      <td>256</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>102.882131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>23/06/2020</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>31390</td>\n",
       "      <td>427</td>\n",
       "      <td>USA</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>329064917.0</td>\n",
       "      <td>America</td>\n",
       "      <td>106.701438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dateRep  day  month  year  cases  deaths  \\\n",
       "parsed_date                                                \n",
       "2019-12-31   31/12/2019   31     12  2019      0       0   \n",
       "2020-07-16   16/07/2020   16      7  2020  67717     953   \n",
       "2020-05-13   13/05/2020   13      5  2020  22048    1703   \n",
       "2020-06-17   17/06/2020   17      6  2020  23705     836   \n",
       "2020-06-18   18/06/2020   18      6  2020  25559     754   \n",
       "2020-06-19   19/06/2020   19      6  2020  27762     717   \n",
       "2020-06-20   20/06/2020   20      6  2020  29909     678   \n",
       "2020-06-21   21/06/2020   21      6  2020  34158     607   \n",
       "2020-06-22   22/06/2020   22      6  2020  25793     256   \n",
       "2020-06-23   23/06/2020   23      6  2020  31390     427   \n",
       "\n",
       "            countriesAndTerritories geoId countryterritoryCode  popData2019  \\\n",
       "parsed_date                                                                   \n",
       "2019-12-31                      USA    US                  USA  329064917.0   \n",
       "2020-07-16                      USA    US                  USA  329064917.0   \n",
       "2020-05-13                      USA    US                  USA  329064917.0   \n",
       "2020-06-17                      USA    US                  USA  329064917.0   \n",
       "2020-06-18                      USA    US                  USA  329064917.0   \n",
       "2020-06-19                      USA    US                  USA  329064917.0   \n",
       "2020-06-20                      USA    US                  USA  329064917.0   \n",
       "2020-06-21                      USA    US                  USA  329064917.0   \n",
       "2020-06-22                      USA    US                  USA  329064917.0   \n",
       "2020-06-23                      USA    US                  USA  329064917.0   \n",
       "\n",
       "            continentExp  \\\n",
       "parsed_date                \n",
       "2019-12-31       America   \n",
       "2020-07-16       America   \n",
       "2020-05-13       America   \n",
       "2020-06-17       America   \n",
       "2020-06-18       America   \n",
       "2020-06-19       America   \n",
       "2020-06-20       America   \n",
       "2020-06-21       America   \n",
       "2020-06-22       America   \n",
       "2020-06-23       America   \n",
       "\n",
       "             Cumulative_number_for_14_days_of_COVID-19_cases_per_100000  \n",
       "parsed_date                                                              \n",
       "2019-12-31                                                 NaN           \n",
       "2020-07-16                                          247.006277           \n",
       "2020-05-13                                          108.605014           \n",
       "2020-06-17                                           92.963420           \n",
       "2020-06-18                                           94.744223           \n",
       "2020-06-19                                           96.756592           \n",
       "2020-06-20                                           98.194302           \n",
       "2020-06-21                                          101.821246           \n",
       "2020-06-22                                          102.882131           \n",
       "2020-06-23                                          106.701438           "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update all occurrences of United_States_of_America and United Kingdom to USA and UK respectively\n",
    "covid['countriesAndTerritories'] = covid['countriesAndTerritories'].replace('United_States_of_America', 'USA')\n",
    "covid['countriesAndTerritories'] = covid['countriesAndTerritories'].replace('United_Kingdom', 'UK')\n",
    "\n",
    "# Define custom sorting order\n",
    "custom_order = ['USA', 'UK']\n",
    "\n",
    "# Sort the index based on the custom sorting order\n",
    "covid.sort_values(by='countriesAndTerritories', key=lambda x: x.map({k: i for i, k in enumerate(custom_order)}), inplace=True)\n",
    "covid.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49b7f3ca-8616-4a13-87cb-e044a1060ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               dateRep  day  month  year  cases  deaths  \\\n",
      "date                                                      \n",
      "2020-01-18  18/01/2020   18      1  2020      0       0   \n",
      "2020-01-18  18/01/2020   18      1  2020      0       0   \n",
      "2020-01-18  18/01/2020   18      1  2020      0       0   \n",
      "2020-01-18  18/01/2020   18      1  2020      0       0   \n",
      "2020-01-18  18/01/2020   18      1  2020      0       0   \n",
      "\n",
      "           countriesAndTerritories geoId countryterritoryCode  popData2019  \\\n",
      "date                                                                         \n",
      "2020-01-18                 Croatia    HR                  HRV    4076246.0   \n",
      "2020-01-18                  Greece    EL                  GRC   10724599.0   \n",
      "2020-01-18                      UK    UK                  GBR   66647112.0   \n",
      "2020-01-18              Azerbaijan    AZ                  AZE   10047719.0   \n",
      "2020-01-18                 Bahrain    BH                  BHR    1641164.0   \n",
      "\n",
      "           continentExp  \\\n",
      "date                      \n",
      "2020-01-18       Europe   \n",
      "2020-01-18       Europe   \n",
      "2020-01-18       Europe   \n",
      "2020-01-18       Europe   \n",
      "2020-01-18         Asia   \n",
      "\n",
      "            Cumulative_number_for_14_days_of_COVID-19_cases_per_100000  \n",
      "date                                                                    \n",
      "2020-01-18                                                0.0           \n",
      "2020-01-18                                                0.0           \n",
      "2020-01-18                                                0.0           \n",
      "2020-01-18                                                0.0           \n",
      "2020-01-18                                                0.0           \n"
     ]
    }
   ],
   "source": [
    "# Sort the index\n",
    "covid_parsed.sort_index(inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(covid_parsed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e77338-3f39-4680-a086-8ad6251951ca",
   "metadata": {},
   "source": [
    "## 2\n",
    "With the `earthquake.csv` file, select all earthquakes in Japan with a magnitude of 4 or greater. Display them sorted by time. Only output the magnitude and the place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b0d6439-acb7-424f-830d-f3f3d42ce128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>time</th>\n",
       "      <th>place</th>\n",
       "      <th>tsunami</th>\n",
       "      <th>parsed_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.35</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539475168010</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.29</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539475129610</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.42</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539475062610</td>\n",
       "      <td>8km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539474978070</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.16</td>\n",
       "      <td>md</td>\n",
       "      <td>1539474716050</td>\n",
       "      <td>10km NW of Avenal, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>0.62</td>\n",
       "      <td>md</td>\n",
       "      <td>1537230228060</td>\n",
       "      <td>9km ENE of Mammoth Lakes, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>1.00</td>\n",
       "      <td>ml</td>\n",
       "      <td>1537230135130</td>\n",
       "      <td>3km W of Julian, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>2.40</td>\n",
       "      <td>md</td>\n",
       "      <td>1537229908180</td>\n",
       "      <td>35km NNE of Hatillo, Puerto Rico</td>\n",
       "      <td>0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>1.10</td>\n",
       "      <td>ml</td>\n",
       "      <td>1537229545350</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9331</th>\n",
       "      <td>0.66</td>\n",
       "      <td>ml</td>\n",
       "      <td>1537228864470</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9332 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mag magType           time                             place  tsunami  \\\n",
       "0     1.35      ml  1539475168010             9km NE of Aguanga, CA        0   \n",
       "1     1.29      ml  1539475129610             9km NE of Aguanga, CA        0   \n",
       "2     3.42      ml  1539475062610             8km NE of Aguanga, CA        0   \n",
       "3     0.44      ml  1539474978070             9km NE of Aguanga, CA        0   \n",
       "4     2.16      md  1539474716050             10km NW of Avenal, CA        0   \n",
       "...    ...     ...            ...                               ...      ...   \n",
       "9327  0.62      md  1537230228060      9km ENE of Mammoth Lakes, CA        0   \n",
       "9328  1.00      ml  1537230135130               3km W of Julian, CA        0   \n",
       "9329  2.40      md  1537229908180  35km NNE of Hatillo, Puerto Rico        0   \n",
       "9330  1.10      ml  1537229545350             9km NE of Aguanga, CA        0   \n",
       "9331  0.66      ml  1537228864470             9km NE of Aguanga, CA        0   \n",
       "\n",
       "     parsed_place  \n",
       "0      California  \n",
       "1      California  \n",
       "2      California  \n",
       "3      California  \n",
       "4      California  \n",
       "...           ...  \n",
       "9327   California  \n",
       "9328   California  \n",
       "9329  Puerto Rico  \n",
       "9330   California  \n",
       "9331   California  \n",
       "\n",
       "[9332 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read earthquake/quake- file\n",
    "quakes = pd.read_csv(datapath / Path('earthquake.csv'))\n",
    "\n",
    "# Print the dataframe to view the data\n",
    "quakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0eaf0ef-9b8c-40de-a8e5-56f9ef15f4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mag                             place\n",
      "9198  4.6          3km ESE of Sugito, Japan\n",
      "9083  5.1     23km ENE of Ishinomaki, Japan\n",
      "9070  4.7           96km E of Hasaki, Japan\n",
      "8687  4.2          39km NE of Misawa, Japan\n",
      "8555  4.6        105km ENE of Miyako, Japan\n",
      "8550  4.4        105km ENE of Miyako, Japan\n",
      "8431  4.6            171km E of Nago, Japan\n",
      "8376  4.4            171km E of Nago, Japan\n",
      "8327  4.2        34km ESE of Chitose, Japan\n",
      "8324  4.6            167km E of Nago, Japan\n",
      "8311  4.4            166km E of Nago, Japan\n",
      "8071  4.4           67km E of Nemuro, Japan\n",
      "7832  5.3            169km E of Nago, Japan\n",
      "7807  4.4   67km NNE of Hachijo-jima, Japan\n",
      "7696  4.0         65km E of Shizunai, Japan\n",
      "7652  4.2            164km E of Nago, Japan\n",
      "7408  4.8         65km SSE of Hasaki, Japan\n",
      "7381  4.6    9km ENE of Funaishikawa, Japan\n",
      "7261  4.1          64km ESE of Owase, Japan\n",
      "7145  4.1         97km N of Mombetsu, Japan\n",
      "7066  4.4        35km E of Tomakomai, Japan\n",
      "7001  4.3        25km ESE of Muroran, Japan\n",
      "6961  4.7         46km ENE of Hirara, Japan\n",
      "6769  4.8         58km SE of Ofunato, Japan\n",
      "5915  4.4         78km ESE of Yamada, Japan\n",
      "5655  4.6          156km ENE of Nago, Japan\n",
      "4846  4.5        25km ESE of Chitose, Japan\n",
      "4409  5.0        33km NW of Shizunai, Japan\n",
      "4257  4.6   213km SE of Hachijo-jima, Japan\n",
      "4192  4.3       50km NNE of Shizunai, Japan\n",
      "4082  4.8          31km E of Chitose, Japan\n",
      "3851  4.7            173km E of Nago, Japan\n",
      "3771  4.5       87km ESE of Kamaishi, Japan\n",
      "3632  4.9        53km ESE of Hitachi, Japan\n",
      "3072  4.9         15km ENE of Hasaki, Japan\n",
      "2824  4.4        51km SSE of Kushima, Japan\n",
      "2688  4.0         51km WNW of Mikuni, Japan\n",
      "2591  5.0            144km E of Nago, Japan\n",
      "2576  5.4        37km E of Tomakomai, Japan\n",
      "2564  4.6            162km E of Nago, Japan\n",
      "2191  4.6        27km ESE of Chitose, Japan\n",
      "2053  4.8            147km E of Nago, Japan\n",
      "1898  4.8        12km N of Shinshiro, Japan\n",
      "1875  4.7  177km WSW of Chichi-shima, Japan\n",
      "1732  4.1          89km NE of Miyako, Japan\n",
      "1563  4.9      293km ESE of Iwo Jima, Japan\n",
      "1492  4.6        29km E of Tomakomai, Japan\n",
      "1435  4.4        21km E of Tomakomai, Japan\n",
      "1422  4.7            41km E of Namie, Japan\n",
      "1398  4.4   65km NNE of Hachijo-jima, Japan\n",
      "1309  4.5         80km ENE of Misawa, Japan\n",
      "1124  4.6       53km ESE of Kamaishi, Japan\n",
      "713   4.7          139km WSW of Naze, Japan\n",
      "536   4.5        14km E of Tomakomai, Japan\n",
      "476   5.2           7km ESE of Asahi, Japan\n",
      "67    4.6          160km NNW of Nago, Japan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read earthquake data from the CSV file\n",
    "quakes = pd.read_csv('earthquake.csv', parse_dates=['time'])\n",
    "\n",
    "# Filter earthquakes in Japan with a magnitude of 4 or greater\n",
    "japan_earthquakes = quakes[(quakes['mag'] >= 4) & (quakes['place'].str.contains('Japan', case=False, na=False))]\n",
    "\n",
    "# Display selected columns sorted by time\n",
    "result = japan_earthquakes[['mag', 'place', 'time']].sort_values(by='time')\n",
    "\n",
    "# Print the result\n",
    "print(result[['mag', 'place']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6fe8ec-1d31-4e20-84ce-7056f1be8219",
   "metadata": {},
   "source": [
    "## 3\n",
    "Create bins for each full number of earthquake magnitude (magType = 'ml') and count how many are in each bin. Output them in magnitude order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91821edb-2a69-4021-b575-052265a8582c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  magnitude_bin  count\n",
      "0       [-1, 0)    446\n",
      "1        [0, 1)   2072\n",
      "2        [1, 2)   3126\n",
      "3        [2, 3)    985\n",
      "4        [3, 4)    153\n",
      "5        [4, 5)      6\n",
      "6        [5, 6)      2\n"
     ]
    }
   ],
   "source": [
    "# Filter earthquakes with magnitude type 'ml'\n",
    "ml_quakes = quakes[quakes['magType'] == 'ml'].copy()  # Make a copy to avoid the SettingWithCopyWarning\n",
    "\n",
    "# Create bins for each full number of earthquake magnitude\n",
    "bins = list(range(int(ml_quakes['mag'].min()), int(ml_quakes['mag'].max()) + 2))\n",
    "\n",
    "# Create a new column 'magnitude_bin' based on the bins\n",
    "ml_quakes['magnitude_bin'] = pd.cut(ml_quakes['mag'], bins=bins, right=False, include_lowest=True)\n",
    "\n",
    "# Count the number of earthquakes in each bin\n",
    "earthquake_counts = ml_quakes.groupby('magnitude_bin').size().reset_index(name='count')\n",
    "\n",
    "# Sort by magnitude\n",
    "earthquake_counts.sort_values(by='magnitude_bin', inplace=True)\n",
    "\n",
    "# Print the result\n",
    "print(earthquake_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558b121-44ee-42c9-a1ae-776d3261b968",
   "metadata": {},
   "source": [
    "## 4\n",
    "Using the `faang.csv`: Group by ticker and resample to monthly.\n",
    "\n",
    "Make the following aggregations:\n",
    "- Mean opening price\n",
    "- Max high price\n",
    "- Min low price\n",
    "- Mean closing price\n",
    "- Sum of volume traded\n",
    "\n",
    "Floating point numbers should have two decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e5ff5ac-b211-456e-9541-272999468182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>FB</td>\n",
       "      <td>181.580002</td>\n",
       "      <td>177.550003</td>\n",
       "      <td>177.679993</td>\n",
       "      <td>181.419998</td>\n",
       "      <td>18151900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>FB</td>\n",
       "      <td>184.779999</td>\n",
       "      <td>181.330002</td>\n",
       "      <td>181.880005</td>\n",
       "      <td>184.669998</td>\n",
       "      <td>16886600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>FB</td>\n",
       "      <td>186.210007</td>\n",
       "      <td>184.100006</td>\n",
       "      <td>184.899994</td>\n",
       "      <td>184.330002</td>\n",
       "      <td>13880900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>FB</td>\n",
       "      <td>186.899994</td>\n",
       "      <td>184.929993</td>\n",
       "      <td>185.589996</td>\n",
       "      <td>186.850006</td>\n",
       "      <td>13574500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>FB</td>\n",
       "      <td>188.899994</td>\n",
       "      <td>186.330002</td>\n",
       "      <td>187.199997</td>\n",
       "      <td>188.279999</td>\n",
       "      <td>17994700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>1003.539978</td>\n",
       "      <td>970.109985</td>\n",
       "      <td>973.900024</td>\n",
       "      <td>976.219971</td>\n",
       "      <td>1590300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>983.000000</td>\n",
       "      <td>989.010010</td>\n",
       "      <td>1039.459961</td>\n",
       "      <td>2373300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>1043.890015</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>1017.150024</td>\n",
       "      <td>1043.880005</td>\n",
       "      <td>2109800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>1055.560059</td>\n",
       "      <td>1033.099976</td>\n",
       "      <td>1049.619995</td>\n",
       "      <td>1037.079956</td>\n",
       "      <td>1414800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>1052.699951</td>\n",
       "      <td>1023.590027</td>\n",
       "      <td>1050.959961</td>\n",
       "      <td>1035.609985</td>\n",
       "      <td>1493300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ticker         high          low         open        close  \\\n",
       "date                                                                    \n",
       "2018-01-02     FB   181.580002   177.550003   177.679993   181.419998   \n",
       "2018-01-03     FB   184.779999   181.330002   181.880005   184.669998   \n",
       "2018-01-04     FB   186.210007   184.100006   184.899994   184.330002   \n",
       "2018-01-05     FB   186.899994   184.929993   185.589996   186.850006   \n",
       "2018-01-08     FB   188.899994   186.330002   187.199997   188.279999   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "2018-12-24   GOOG  1003.539978   970.109985   973.900024   976.219971   \n",
       "2018-12-26   GOOG  1040.000000   983.000000   989.010010  1039.459961   \n",
       "2018-12-27   GOOG  1043.890015   997.000000  1017.150024  1043.880005   \n",
       "2018-12-28   GOOG  1055.560059  1033.099976  1049.619995  1037.079956   \n",
       "2018-12-31   GOOG  1052.699951  1023.590027  1050.959961  1035.609985   \n",
       "\n",
       "                volume  \n",
       "date                    \n",
       "2018-01-02  18151900.0  \n",
       "2018-01-03  16886600.0  \n",
       "2018-01-04  13880900.0  \n",
       "2018-01-05  13574500.0  \n",
       "2018-01-08  17994700.0  \n",
       "...                ...  \n",
       "2018-12-24   1590300.0  \n",
       "2018-12-26   2373300.0  \n",
       "2018-12-27   2109800.0  \n",
       "2018-12-28   1414800.0  \n",
       "2018-12-31   1493300.0  \n",
       "\n",
       "[1255 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read faang csv file\n",
    "faang = pd.read_csv(datapath / Path('faang.csv'), index_col='date', parse_dates=True)\n",
    "\n",
    "# Print data from dataframe\n",
    "faang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cbf19ab-9567-49a6-9428-348ce23e400e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ticker         high          low         open        close  \\\n",
      "ticker date                                                                    \n",
      "AAPL   2018-01-31   AAPL    42.110001    41.625000    41.717499    41.857498   \n",
      "       2018-02-28   AAPL    45.154999    44.512501    44.814999    44.529999   \n",
      "       2018-03-31   AAPL    42.937500    41.724998    41.952499    41.945000   \n",
      "       2018-04-30   AAPL    41.814999    40.459999    40.532501    41.314999   \n",
      "       2018-05-31   AAPL    47.057499    46.535000    46.805000    46.717499   \n",
      "       2018-06-30   AAPL    46.797501    45.727501    46.572498    46.277500   \n",
      "       2018-07-31   AAPL    48.035000    47.334999    47.575001    47.572498   \n",
      "       2018-08-31   AAPL    57.217499    56.500000    56.627499    56.907501   \n",
      "       2018-09-30   AAPL    56.459999    56.005001    56.197498    56.435001   \n",
      "       2018-10-31   AAPL    55.112499    54.154999    54.220001    54.715000   \n",
      "       2018-11-30   AAPL    45.082500    44.257500    45.072498    44.645000   \n",
      "       2018-12-31   AAPL    39.840000    39.119999    39.632500    39.435001   \n",
      "AMZN   2018-01-31   AMZN  1472.579956  1450.040039  1451.300049  1450.890015   \n",
      "       2018-02-28   AMZN  1528.699951  1512.000000  1519.510010  1512.449951   \n",
      "       2018-03-31   AMZN  1455.469971  1365.199951  1406.000000  1447.339966   \n",
      "       2018-04-30   AMZN  1596.000000  1560.939941  1582.500000  1566.130005   \n",
      "       2018-05-31   AMZN  1635.000000  1621.349976  1623.000000  1629.619995   \n",
      "       2018-06-30   AMZN  1723.410034  1694.319946  1717.000000  1699.800049   \n",
      "       2018-07-31   AMZN  1801.829956  1739.319946  1786.489990  1777.439941   \n",
      "       2018-08-31   AMZN  2022.380005  2004.739990  2007.000000  2012.709961   \n",
      "       2018-09-30   AMZN  2026.520020  1996.459961  2004.410034  2003.000000   \n",
      "       2018-10-31   AMZN  1623.910034  1565.089966  1569.989990  1598.010010   \n",
      "       2018-11-30   AMZN  1696.000000  1666.500000  1679.500000  1690.170044   \n",
      "       2018-12-31   AMZN  1520.760010  1487.000000  1510.800049  1501.969971   \n",
      "FB     2018-01-31     FB   189.830002   185.220001   188.369995   186.889999   \n",
      "       2018-02-28     FB   182.880005   178.139999   182.300003   178.320007   \n",
      "       2018-03-31     FB   161.419998   154.139999   155.149994   159.789993   \n",
      "       2018-04-30     FB   175.720001   171.710007   173.789993   172.000000   \n",
      "       2018-05-31     FB   192.720001   187.479996   187.869995   191.779999   \n",
      "       2018-06-30     FB   197.600006   193.960007   197.320007   194.320007   \n",
      "       2018-07-31     FB   174.240005   170.000000   170.669998   172.580002   \n",
      "       2018-08-31     FB   177.619995   174.979996   177.149994   175.729996   \n",
      "       2018-09-30     FB   168.789993   162.559998   168.330002   164.460007   \n",
      "       2018-10-31     FB   156.399994   148.960007   155.000000   151.789993   \n",
      "       2018-11-30     FB   140.970001   137.360001   138.259995   140.610001   \n",
      "       2018-12-31     FB   134.639999   129.949997   134.449997   131.089996   \n",
      "GOOG   2018-01-31   GOOG  1173.000000  1159.130005  1170.569946  1169.939941   \n",
      "       2018-02-28   GOOG  1127.530029  1103.239990  1123.030029  1104.729980   \n",
      "       2018-03-31   GOOG  1043.000000  1002.900024  1011.630005  1031.790039   \n",
      "       2018-04-30   GOOG  1037.000000  1016.849976  1030.010010  1017.330017   \n",
      "       2018-05-31   GOOG  1097.189941  1067.560059  1067.560059  1084.989990   \n",
      "       2018-06-30   GOOG  1128.227051  1115.000000  1120.000000  1115.650024   \n",
      "       2018-07-31   GOOG  1227.588013  1205.599976  1220.010010  1217.260010   \n",
      "       2018-08-31   GOOG  1238.660034  1211.285034  1234.979980  1218.189941   \n",
      "       2018-09-30   GOOG  1195.410034  1184.500000  1191.869995  1193.469971   \n",
      "       2018-10-31   GOOG  1091.939941  1057.000000  1059.810059  1076.770020   \n",
      "       2018-11-30   GOOG  1095.569946  1077.880005  1089.069946  1094.430054   \n",
      "       2018-12-31   GOOG  1052.699951  1023.590027  1050.959961  1035.609985   \n",
      "NFLX   2018-01-31   NFLX   282.290009   269.579987   281.940002   270.299988   \n",
      "       2018-02-28   NFLX   295.750000   290.779999   293.100006   291.380005   \n",
      "       2018-03-31   NFLX   295.350006   275.899994   287.000000   295.350006   \n",
      "       2018-04-30   NFLX   317.880005   310.119995   311.070007   312.459991   \n",
      "       2018-05-31   NFLX   355.529999   350.209991   353.799988   351.600006   \n",
      "       2018-06-30   NFLX   401.329987   390.549988   399.190002   391.429993   \n",
      "       2018-07-31   NFLX   342.500000   328.000000   331.510010   337.450012   \n",
      "       2018-08-31   NFLX   376.000000   367.079987   370.660004   367.679993   \n",
      "       2018-09-30   NFLX   380.799988   373.730011   379.239990   374.130005   \n",
      "       2018-10-31   NFLX   311.500000   295.049988   297.769989   301.779999   \n",
      "       2018-11-30   NFLX   290.809998   283.059998   288.000000   286.130005   \n",
      "       2018-12-31   NFLX   270.100006   260.000000   260.160004   267.660004   \n",
      "\n",
      "                        volume  \n",
      "ticker date                     \n",
      "AAPL   2018-01-31  129915600.0  \n",
      "       2018-02-28  151128400.0  \n",
      "       2018-03-31  153594000.0  \n",
      "       2018-04-30  169709600.0  \n",
      "       2018-05-31  109931200.0  \n",
      "       2018-06-30   90950800.0  \n",
      "       2018-07-31  157492000.0  \n",
      "       2018-08-31  173360400.0  \n",
      "       2018-09-30   91717600.0  \n",
      "       2018-10-31  153435600.0  \n",
      "       2018-11-30  158126000.0  \n",
      "       2018-12-31  140014000.0  \n",
      "AMZN   2018-01-31    6424700.0  \n",
      "       2018-02-28    4515000.0  \n",
      "       2018-03-31   12581100.0  \n",
      "       2018-04-30    5464100.0  \n",
      "       2018-05-31    3166300.0  \n",
      "       2018-06-30    4543500.0  \n",
      "       2018-07-31    5738700.0  \n",
      "       2018-08-31    4204400.0  \n",
      "       2018-09-30    4085100.0  \n",
      "       2018-10-31    9390200.0  \n",
      "       2018-11-30    5761800.0  \n",
      "       2018-12-31    6954500.0  \n",
      "FB     2018-01-31   43275100.0  \n",
      "       2018-02-28   18783000.0  \n",
      "       2018-03-31   59434300.0  \n",
      "       2018-04-30   20750500.0  \n",
      "       2018-05-31   30782600.0  \n",
      "       2018-06-30   15811600.0  \n",
      "       2018-07-31   40356500.0  \n",
      "       2018-08-31   18065200.0  \n",
      "       2018-09-30   34265600.0  \n",
      "       2018-10-31   60101300.0  \n",
      "       2018-11-30   25732600.0  \n",
      "       2018-12-31   24625300.0  \n",
      "GOOG   2018-01-31    1538700.0  \n",
      "       2018-02-28    1882600.0  \n",
      "       2018-03-31    2726800.0  \n",
      "       2018-04-30    1671300.0  \n",
      "       2018-05-31    3088300.0  \n",
      "       2018-06-30    1315100.0  \n",
      "       2018-07-31    1644700.0  \n",
      "       2018-08-31    1816400.0  \n",
      "       2018-09-30    1380600.0  \n",
      "       2018-10-31    2529800.0  \n",
      "       2018-11-30    2580200.0  \n",
      "       2018-12-31    1493300.0  \n",
      "NFLX   2018-01-31   11695100.0  \n",
      "       2018-02-28    7653500.0  \n",
      "       2018-03-31   19145500.0  \n",
      "       2018-04-30    6088800.0  \n",
      "       2018-05-31    6921700.0  \n",
      "       2018-06-30    9252500.0  \n",
      "       2018-07-31   14085400.0  \n",
      "       2018-08-31    7943400.0  \n",
      "       2018-09-30    7114900.0  \n",
      "       2018-10-31   20360300.0  \n",
      "       2018-11-30   11860100.0  \n",
      "       2018-12-31   13508900.0  \n"
     ]
    }
   ],
   "source": [
    "# Group by ticker and resample to monthly.\n",
    "\n",
    "# Read the faang.csv file\n",
    "faang = pd.read_csv('faang.csv', index_col='date', parse_dates=True)\n",
    "\n",
    "# Group by ticker and resample to monthly frequency\n",
    "faang_monthly = faang.groupby('ticker').resample('M').last()\n",
    "\n",
    "# Print the result\n",
    "print(faang_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4db3a99-d02a-4352-b662-12308cbbc387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker\n",
      "AAPL      47.28\n",
      "AMZN    1644.07\n",
      "FB       171.47\n",
      "GOOG    1113.55\n",
      "NFLX     319.62\n",
      "Name: open, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Mean opening price\n",
    "\n",
    "# Read the faang.csv file\n",
    "faang = pd.read_csv('faang.csv', parse_dates=True)\n",
    "\n",
    "# Convert 'date' to datetime format\n",
    "faang['date'] = pd.to_datetime(faang['date'])\n",
    "\n",
    "# Group by 'ticker' and calculate the mean opening price with two decimal places\n",
    "mean_opening_price = faang.groupby('ticker')['open'].mean().round(2)\n",
    "\n",
    "# Print the result\n",
    "print(mean_opening_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4fe09a1-48a9-4ba4-918d-82e7cf885516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker\n",
      "AAPL      58.37\n",
      "AMZN    2050.50\n",
      "FB       218.62\n",
      "GOOG    1273.89\n",
      "NFLX     423.21\n",
      "Name: high, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Max high price \n",
    "\n",
    "# Read the faang.csv file\n",
    "faang = pd.read_csv('faang.csv', parse_dates=True)\n",
    "\n",
    "# Convert 'date' to datetime format\n",
    "faang['date'] = pd.to_datetime(faang['date'])\n",
    "\n",
    "# Group by 'ticker' and calculate the maximum high price with two decimal places\n",
    "max_high_price = faang.groupby('ticker')['high'].max().round(2)\n",
    "\n",
    "# Print the result\n",
    "print(max_high_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f348e5e-b71b-48a6-952e-dab2c6fae513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker\n",
      "AAPL      36.65\n",
      "AMZN    1170.51\n",
      "FB       123.02\n",
      "GOOG     970.11\n",
      "NFLX     195.42\n",
      "Name: low, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Min low price\n",
    "\n",
    "# Read the faang.csv file\n",
    "faang = pd.read_csv('faang.csv', parse_dates=True)\n",
    "\n",
    "# Convert 'date' to datetime format\n",
    "faang['date'] = pd.to_datetime(faang['date'])\n",
    "\n",
    "# Group by 'ticker' and calculate the minimum low price with two decimal places\n",
    "min_low_price = faang.groupby('ticker')['low'].min().round(2)\n",
    "\n",
    "# Print the result\n",
    "print(min_low_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9b48497-5e0a-48f1-8d81-fbdd718e933b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker\n",
      "AAPL      47.26\n",
      "AMZN    1641.73\n",
      "FB       171.51\n",
      "GOOG    1113.23\n",
      "NFLX     319.29\n",
      "Name: close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Mean closing price\n",
    "\n",
    "# Read the faang.csv file\n",
    "faang = pd.read_csv('faang.csv', parse_dates=True)\n",
    "\n",
    "# Convert 'date' to datetime format\n",
    "faang['date'] = pd.to_datetime(faang['date'])\n",
    "\n",
    "# Group by 'ticker' and calculate the mean closing price with two decimal places\n",
    "mean_closing_price = faang.groupby('ticker')['close'].mean().round(2)\n",
    "\n",
    "# Print the result\n",
    "print(mean_closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd526c05-246a-45cc-b8cd-0c3bb7ae7b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker\n",
      "AAPL    34,156,144,800.00\n",
      "AMZN     1,417,897,600.00\n",
      "FB       6,942,307,800.00\n",
      "GOOG       437,233,300.00\n",
      "NFLX     2,878,875,800.00\n",
      "Name: volume, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Sum of volume traded\n",
    "\n",
    "# Read the faang.csv file\n",
    "faang = pd.read_csv('faang.csv', parse_dates=True)\n",
    "\n",
    "# Convert 'date' to datetime format\n",
    "faang['date'] = pd.to_datetime(faang['date'])\n",
    "\n",
    "# Group by 'ticker' and calculate the sum of the volume traded, rounded to two decimal places\n",
    "sum_volume_traded = faang.groupby('ticker')['volume'].sum().round(2)\n",
    "\n",
    "# Format the result to have commas as thousands separators\n",
    "formatted_sum_volume_traded = sum_volume_traded.map('{:,.2f}'.format)\n",
    "\n",
    "# Print the formatted result\n",
    "print(formatted_sum_volume_traded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24a421-f993-4827-8ab4-137ce670c457",
   "metadata": {},
   "source": [
    "## 5\n",
    "\n",
    "Calculate the z-scores for each numeric column of Amazon's data (faang.csv) but only for Q4 of 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "049a5f1b-c036-4cd0-8239-45298e716683",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         high       low      open     close    volume\n",
      "690  2.368006  2.502113  2.337813  2.385848 -1.630411\n",
      "691  2.227302  2.247433  2.190795  2.155037 -0.861879\n",
      "692  2.058955  2.139987  2.068570  2.025489 -0.920345\n",
      "693  1.819474  1.781561  1.850048  1.722816 -0.126582\n",
      "694  1.628173  1.554416  1.642819  1.584748 -0.298771\n",
      "..        ...       ...       ...       ...       ...\n",
      "748 -2.159820 -2.187566 -2.179582 -2.226185 -0.141238\n",
      "749 -1.611714 -1.810493 -2.026617 -1.339674  1.123063\n",
      "750 -1.641276 -1.626703 -1.456521 -1.404343  0.849827\n",
      "751 -1.325261 -1.231588 -1.328549 -1.289951  0.496102\n",
      "752 -1.273456 -0.975763 -1.078283 -1.122691 -0.246405\n",
      "\n",
      "[63 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the faang.csv file\n",
    "faang = pd.read_csv('faang.csv', parse_dates=True)\n",
    "\n",
    "# Convert 'date' to datetime format\n",
    "faang['date'] = pd.to_datetime(faang['date'])\n",
    "\n",
    "# Filter data for Amazon (AMZN) in Q4 of 2018\n",
    "amazon_q4_2018 = faang[(faang['ticker'] == 'AMZN') & (faang['date'].dt.year == 2018) & (faang['date'].dt.quarter == 4)]\n",
    "\n",
    "# Exclude non-numeric columns from z-score calculation\n",
    "numeric_columns = amazon_q4_2018.select_dtypes(include=['float64', 'int64']).columns\n",
    "z_scores_amazon_q4_2018 = (amazon_q4_2018[numeric_columns] - amazon_q4_2018[numeric_columns].mean()) / amazon_q4_2018[numeric_columns].std()\n",
    "\n",
    "# Print the z-scores for Amazon in Q4 of 2018\n",
    "print(z_scores_amazon_q4_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ce17a-0cfd-4912-94e8-a1fc197a622f",
   "metadata": {},
   "source": [
    "## 6\n",
    "Represent all the values in the FAANG dataset in terms of the first date in the data. To do so, divide all values for each ticker by the values of the first date in the data for that ticker. When data is in this format, we can easily see growth over time.\n",
    "Show only the first 5 days per ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68518775-a072-4e61-bcc5-480e4981fbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ticker       date      high       low      open     close    volume\n",
      "0        FB 2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "1        FB 2018-01-03  1.017623  1.021290  1.023638  1.017914  0.930294\n",
      "2        FB 2018-01-04  1.025498  1.036891  1.040635  1.016040  0.764708\n",
      "3        FB 2018-01-05  1.029298  1.041566  1.044518  1.029931  0.747828\n",
      "4        FB 2018-01-08  1.040313  1.049451  1.053579  1.037813  0.991340\n",
      "251    AAPL 2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "252    AAPL 2018-01-03  1.013059  1.015952  1.013928  0.999826  1.155033\n",
      "253    AAPL 2018-01-04  1.006790  1.016661  1.013987  1.004470  0.877864\n",
      "254    AAPL 2018-01-05  1.017818  1.022392  1.019276  1.015906  0.925814\n",
      "255    AAPL 2018-01-08  1.019211  1.027591  1.024624  1.012133  0.804816\n",
      "502    AMZN 2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "503    AMZN 2018-01-03  1.013017  1.015199  1.013908  1.012775  1.153758\n",
      "504    AMZN 2018-01-04  1.021739  1.029175  1.028157  1.017308  1.121581\n",
      "505    AMZN 2018-01-05  1.032891  1.033737  1.038831  1.033751  1.315532\n",
      "506    AMZN 2018-01-08  1.053008  1.052558  1.054608  1.048662  1.588235\n",
      "753    NFLX 2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "754    NFLX 2018-01-03  1.022614  1.031112  1.030342  1.019794  0.783394\n",
      "755    NFLX 2018-01-04  1.026779  1.043905  1.051504  1.022679  0.549800\n",
      "756    NFLX 2018-01-05  1.041508  1.052042  1.056859  1.044363  0.641312\n",
      "757    NFLX 2018-01-08  1.053806  1.066626  1.070984  1.054608  0.508822\n",
      "1004   GOOG 2018-01-02  1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "1005   GOOG 2018-01-03  1.018136  1.017202  1.015234  1.016413  1.155624\n",
      "1006   GOOG 2018-01-04  1.024959  1.037094  1.037831  1.020094  0.811732\n",
      "1007   GOOG 2018-01-05  1.034969  1.044746  1.043555  1.034958  1.033533\n",
      "1008   GOOG 2018-01-08  1.041549  1.053950  1.051405  1.039380  0.846477\n"
     ]
    }
   ],
   "source": [
    "# Read the faang.csv file\n",
    "faang = pd.read_csv('faang.csv', parse_dates=True)\n",
    "\n",
    "# Convert 'date' to datetime format\n",
    "faang['date'] = pd.to_datetime(faang['date'])\n",
    "\n",
    "# Group by 'ticker' and calculate the ratio of each value to the first date's value for that ticker\n",
    "faang_ratio = (\n",
    "    faang.set_index(['ticker', 'date'])\n",
    "    .groupby('ticker', group_keys=False)\n",
    "    .apply(lambda x: x / x.iloc[0])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Display only the first 5 days per ticker\n",
    "first_5_days_per_ticker = faang_ratio.groupby('ticker').head(5)\n",
    "\n",
    "# Print the result\n",
    "print(first_5_days_per_ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84494c85-4884-4942-8959-f5329724c716",
   "metadata": {},
   "source": [
    "## 7\n",
    "In the \n",
    "In the earthquake dataset you want to only leave data for the top 5 countries in terms of number of earthquakes for magType 'ml', 'md' and 'mb'.\n",
    "Also show the number of earthquakes per country for the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec7e6f88-d166-4ba6-84e1-ef1465d2fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of earthquakes per country for magTypes 'ml', 'md', and 'mb':\n",
      "Alaska         3656\n",
      "California     2856\n",
      "Nevada          681\n",
      "Hawaii          367\n",
      "Puerto Rico     216\n",
      "Name: parsed_place, dtype: int64\n",
      "\n",
      "Filtered data for the top 5 countries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>time</th>\n",
       "      <th>place</th>\n",
       "      <th>tsunami</th>\n",
       "      <th>parsed_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.35</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539475168010</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.29</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539475129610</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.42</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539475062610</td>\n",
       "      <td>8km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539474978070</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.16</td>\n",
       "      <td>md</td>\n",
       "      <td>1539474716050</td>\n",
       "      <td>10km NW of Avenal, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>0.62</td>\n",
       "      <td>md</td>\n",
       "      <td>1537230228060</td>\n",
       "      <td>9km ENE of Mammoth Lakes, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>1.00</td>\n",
       "      <td>ml</td>\n",
       "      <td>1537230135130</td>\n",
       "      <td>3km W of Julian, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>2.40</td>\n",
       "      <td>md</td>\n",
       "      <td>1537229908180</td>\n",
       "      <td>35km NNE of Hatillo, Puerto Rico</td>\n",
       "      <td>0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>1.10</td>\n",
       "      <td>ml</td>\n",
       "      <td>1537229545350</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9331</th>\n",
       "      <td>0.66</td>\n",
       "      <td>ml</td>\n",
       "      <td>1537228864470</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mag magType           time                             place  tsunami  \\\n",
       "0     1.35      ml  1539475168010             9km NE of Aguanga, CA        0   \n",
       "1     1.29      ml  1539475129610             9km NE of Aguanga, CA        0   \n",
       "2     3.42      ml  1539475062610             8km NE of Aguanga, CA        0   \n",
       "3     0.44      ml  1539474978070             9km NE of Aguanga, CA        0   \n",
       "4     2.16      md  1539474716050             10km NW of Avenal, CA        0   \n",
       "...    ...     ...            ...                               ...      ...   \n",
       "9327  0.62      md  1537230228060      9km ENE of Mammoth Lakes, CA        0   \n",
       "9328  1.00      ml  1537230135130               3km W of Julian, CA        0   \n",
       "9329  2.40      md  1537229908180  35km NNE of Hatillo, Puerto Rico        0   \n",
       "9330  1.10      ml  1537229545350             9km NE of Aguanga, CA        0   \n",
       "9331  0.66      ml  1537228864470             9km NE of Aguanga, CA        0   \n",
       "\n",
       "     parsed_place  \n",
       "0      California  \n",
       "1      California  \n",
       "2      California  \n",
       "3      California  \n",
       "4      California  \n",
       "...           ...  \n",
       "9327   California  \n",
       "9328   California  \n",
       "9329  Puerto Rico  \n",
       "9330   California  \n",
       "9331   California  \n",
       "\n",
       "[7776 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the earthquake dataset\n",
    "quakes = pd.read_csv('earthquake.csv', parse_dates=['time'])\n",
    "\n",
    "# Filter data for magType 'ml', 'md', and 'mb'\n",
    "filtered_data = quakes[quakes['magType'].isin(['ml', 'md', 'mb'])]\n",
    "\n",
    "# Get the top 5 countries in terms of number of earthquakes\n",
    "top_countries = filtered_data['parsed_place'].value_counts().head(5).index.tolist()\n",
    "\n",
    "# Filter data for the top 5 countries\n",
    "filtered_top_countries = filtered_data[filtered_data['parsed_place'].isin(top_countries)]\n",
    "\n",
    "# Show the number of earthquakes per country\n",
    "earthquakes_per_country = filtered_top_countries['parsed_place'].value_counts()\n",
    "\n",
    "print(\"Number of earthquakes per country for magTypes 'ml', 'md', and 'mb':\")\n",
    "print(earthquakes_per_country)\n",
    "\n",
    "# Show the filtered dataset for the top 5 countries\n",
    "print(\"\\nFiltered data for the top 5 countries:\")\n",
    "filtered_top_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6d092-3a61-42be-bf5c-1177f18d5386",
   "metadata": {},
   "source": [
    "## 8\n",
    "Using seaborn, create a heatmap to visualize the correlation coefficients between earthquake magnitude and whether there was a tsunami with the mb magnitude type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86c7cd4-4424-49fd-85e5-8af5701072f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the earthquake.csv file\n",
    "quakes = pd.read_csv('earthquake.csv', parse_dates=True)\n",
    "\n",
    "# Filter data for 'mb' magnitude type\n",
    "mb_quakes = quakes[quakes['magType'] == 'mb']\n",
    "\n",
    "# Create a correlation matrix\n",
    "correlation_matrix = mb_quakes[['mag', 'tsunami']].corr()\n",
    "\n",
    "# Create a heatmap using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
    "plt.title('Correlation Heatmap: Magnitude vs Tsunami (mb Magnitude Type)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f5238",
   "metadata": {},
   "source": [
    "## 9\n",
    "For the 5 countries with the most covid cases (cumulative), find the day with the largest number of cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c19d292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_2948\\3777500736.py:2: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  covid_data = pd.read_csv('covid.csv', parse_dates=['dateRep'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dateRep   countriesAndTerritories  cases\n",
      "5720  2020-07-30                    Brazil  69074\n",
      "18921 2020-09-17                     India  97894\n",
      "31756 2020-08-17                      Peru  10143\n",
      "33339 2020-07-18                    Russia  12640\n",
      "41828 2020-07-25  United_States_of_America  78427\n"
     ]
    }
   ],
   "source": [
    "# Read the covid.csv file\n",
    "covid_data = pd.read_csv('covid.csv', parse_dates=['dateRep'])\n",
    "\n",
    "covid_data = pd.read_csv('covid.csv', parse_dates=['dateRep'], dayfirst=True, date_parser=lambda x: pd.to_datetime(x, format='%d/%m/%Y'))\n",
    "\n",
    "# Filter data for the 5 countries with the most cumulative cases\n",
    "top_countries_cumulative_cases = covid_data.groupby('countriesAndTerritories')['cases'].sum().nlargest(5).index\n",
    "\n",
    "# Filter the original DataFrame for these countries\n",
    "top_countries_data = covid_data[covid_data['countriesAndTerritories'].isin(top_countries_cumulative_cases)]\n",
    "\n",
    "# Find the day with the largest number of cases for each country\n",
    "day_with_largest_cases = top_countries_data.loc[top_countries_data.groupby('countriesAndTerritories')['cases'].idxmax()]\n",
    "\n",
    "# Print the result\n",
    "print(day_with_largest_cases[['dateRep', 'countriesAndTerritories', 'cases']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57580c38",
   "metadata": {},
   "source": [
    "## 10\n",
    "Find the 7-day average change in COVID-19 cases for the last week in the data for the countries found in part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12646a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     countriesAndTerritories  level_1  daily_change\n",
      "0                     Brazil     5669           NaN\n",
      "1                     Brazil     5670           NaN\n",
      "2                     Brazil     5671           NaN\n",
      "3                     Brazil     5672           NaN\n",
      "4                     Brazil     5673           NaN\n",
      "5                     Brazil     5674           NaN\n",
      "6                     Brazil     5675           NaN\n",
      "7                      India    18919           NaN\n",
      "8                      India    18920           NaN\n",
      "9                      India    18921           NaN\n",
      "10                     India    18922           NaN\n",
      "11                     India    18923           NaN\n",
      "12                     India    18924           NaN\n",
      "13                     India    18925           NaN\n",
      "14                      Peru    31723           NaN\n",
      "15                      Peru    31724           NaN\n",
      "16                      Peru    31725           NaN\n",
      "17                      Peru    31726           NaN\n",
      "18                      Peru    31727           NaN\n",
      "19                      Peru    31728           NaN\n",
      "20                      Peru    31729           NaN\n",
      "21                    Russia    33276           NaN\n",
      "22                    Russia    33277           NaN\n",
      "23                    Russia    33278           NaN\n",
      "24                    Russia    33279           NaN\n",
      "25                    Russia    33280           NaN\n",
      "26                    Russia    33281           NaN\n",
      "27                    Russia    33282           NaN\n",
      "28  United_States_of_America    41772           NaN\n",
      "29  United_States_of_America    41773           NaN\n",
      "30  United_States_of_America    41774           NaN\n",
      "31  United_States_of_America    41775           NaN\n",
      "32  United_States_of_America    41776           NaN\n",
      "33  United_States_of_America    41777           NaN\n",
      "34  United_States_of_America    41778           NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_2948\\4129214830.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_week_data.loc[:, 'daily_change'] = last_week_data.groupby('countriesAndTerritories')['cases'].diff()\n"
     ]
    }
   ],
   "source": [
    "# Read the covid.csv file with explicit date format\n",
    "covid_data = pd.read_csv('covid.csv', parse_dates=['dateRep'], dayfirst=True, date_parser=lambda x: pd.to_datetime(x, format='%d/%m/%Y'))\n",
    "\n",
    "# Filter data for the 5 countries with the most cumulative cases\n",
    "top_countries_cumulative_cases = covid_data.groupby('countriesAndTerritories')['cases'].sum().nlargest(5).index\n",
    "\n",
    "# Filter the original DataFrame for these countries\n",
    "top_countries_data = covid_data[covid_data['countriesAndTerritories'].isin(top_countries_cumulative_cases)]\n",
    "\n",
    "# Find the last week's data for the selected countries\n",
    "last_week_data = top_countries_data[top_countries_data['dateRep'] >= top_countries_data['dateRep'].max() - pd.Timedelta(days=6)]\n",
    "\n",
    "# Calculate the daily change in cases\n",
    "last_week_data.loc[:, 'daily_change'] = last_week_data.groupby('countriesAndTerritories')['cases'].diff()\n",
    "\n",
    "# Calculate the 7-day average change\n",
    "average_change_last_week = last_week_data.groupby('countriesAndTerritories')['daily_change'].rolling(window=7).mean().reset_index()\n",
    "\n",
    "# Print the result\n",
    "print(average_change_last_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b9017",
   "metadata": {},
   "source": [
    "## 11\n",
    "Find the first date that each country other than China had cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59d7f2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    countriesAndTerritories first_date_with_cases\n",
      "0               Afghanistan            2019-12-31\n",
      "1                   Albania            2020-03-09\n",
      "2                   Algeria            2019-12-31\n",
      "3                   Andorra            2020-03-03\n",
      "4                    Angola            2020-03-22\n",
      "..                      ...                   ...\n",
      "204                 Vietnam            2019-12-31\n",
      "205          Western_Sahara            2020-04-26\n",
      "206                   Yemen            2020-04-10\n",
      "207                  Zambia            2020-03-19\n",
      "208                Zimbabwe            2020-03-21\n",
      "\n",
      "[209 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the covid.csv file with explicit date format\n",
    "covid_data = pd.read_csv('covid.csv', parse_dates=['dateRep'], dayfirst=True, date_parser=lambda x: pd.to_datetime(x, format='%d/%m/%Y'))\n",
    "\n",
    "# Filter data for countries other than China\n",
    "countries_other_than_china = covid_data[covid_data['countriesAndTerritories'] != 'China']\n",
    "\n",
    "# Find the first date with cases for each country\n",
    "first_date_with_cases = countries_other_than_china.groupby('countriesAndTerritories')['dateRep'].min().reset_index(name='first_date_with_cases')\n",
    "\n",
    "# Print the result\n",
    "print(first_date_with_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7681960a",
   "metadata": {},
   "source": [
    "## 12\n",
    "Rank the countries by maximum total cases using percentiles. Sort by cases. Replace all _ with blank spaces. Show percentiles with two decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "776c84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               countriesAndTerritories  cases  percentile_rank\n",
      "92                               India  97894           100.00\n",
      "201           United States of America  78427            99.52\n",
      "27                              Brazil  69074            99.05\n",
      "41                               Chile  36179            98.57\n",
      "179                              Spain  27404            98.10\n",
      "..                                 ...    ...              ...\n",
      "109                               Laos      4             1.43\n",
      "24   Bonaire, Saint Eustatius and Saba      4             1.43\n",
      "144           Northern Mariana Islands      4             1.43\n",
      "79                           Greenland      3             0.95\n",
      "5                             Anguilla      2             0.48\n",
      "\n",
      "[210 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the covid.csv file with explicit date format\n",
    "covid_data = pd.read_csv('covid.csv', parse_dates=['dateRep'], dayfirst=True, date_parser=lambda x: pd.to_datetime(x, format='%d/%m/%Y'))\n",
    "\n",
    "# Calculate the maximum total cases for each country\n",
    "max_total_cases = covid_data.groupby('countriesAndTerritories')['cases'].max().reset_index()\n",
    "\n",
    "# Rank the countries by maximum total cases using percentiles\n",
    "max_total_cases['percentile_rank'] = max_total_cases['cases'].rank(pct=True, method='min')\n",
    "\n",
    "# Sort by cases\n",
    "max_total_cases = max_total_cases.sort_values(by='cases', ascending=False)\n",
    "\n",
    "# Replace all _ with blank spaces\n",
    "max_total_cases['countriesAndTerritories'] = max_total_cases['countriesAndTerritories'].str.replace('_', ' ')\n",
    "\n",
    "# Show percentiles with two decimals\n",
    "max_total_cases['percentile_rank'] = (max_total_cases['percentile_rank'] * 100).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(max_total_cases[['countriesAndTerritories', 'cases', 'percentile_rank']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0a846",
   "metadata": {},
   "source": [
    "## 13\n",
    "Write a Python function that matches a word containing 'z', not at the start or end of the word. It should output if it found a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "871b9f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a match: brazen\n",
      "Found a match: amazing\n",
      "Found a match: lazy\n",
      "Found a match: brazil\n"
     ]
    }
   ],
   "source": [
    "def match_word_with_z(word):\n",
    "    # Define the pattern to match a word containing 'z', not at the start or end\n",
    "    pattern = r'\\b\\w*z\\w*\\b'\n",
    "\n",
    "    # Use re.search to find a match\n",
    "    match = re.search(pattern, word)\n",
    "\n",
    "    # Output if a match is found\n",
    "    if match:\n",
    "        print(f\"Found a match: {match.group()}\")\n",
    "    else:\n",
    "        print(\"No match found\")\n",
    "\n",
    "# Example usage:\n",
    "word1 = \"brazen\"\n",
    "word2 = \"amazing\"\n",
    "word3 = \"lazy\"\n",
    "word4 = \"brazil\"\n",
    "\n",
    "match_word_with_z(word1)\n",
    "match_word_with_z(word2)\n",
    "match_word_with_z(word3)\n",
    "match_word_with_z(word4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f0677",
   "metadata": {},
   "source": [
    "## 14\n",
    "Write a Python program to remove leading zeros from an IP address (e.g.: 216.08.094.196 should become 216.8.94.196)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "143f480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original IP address: 216.08.094.196\n",
      "Cleaned IP address: 216.8.94.196\n"
     ]
    }
   ],
   "source": [
    "def remove_leading_zeros(ip_address):\n",
    "    # Split the IP address into octets\n",
    "    octets = ip_address.split('.')\n",
    "\n",
    "    # Remove leading zeros from each octet\n",
    "    cleaned_octets = [str(int(octet)) for octet in octets]\n",
    "\n",
    "    # Join the cleaned octets back into an IP address\n",
    "    cleaned_ip = '.'.join(cleaned_octets)\n",
    "\n",
    "    return cleaned_ip\n",
    "\n",
    "# Example usage:\n",
    "ip_address_with_zeros = \"216.08.094.196\"\n",
    "cleaned_ip_address = remove_leading_zeros(ip_address_with_zeros)\n",
    "\n",
    "print(f\"Original IP address: {ip_address_with_zeros}\")\n",
    "print(f\"Cleaned IP address: {cleaned_ip_address}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55600ee",
   "metadata": {},
   "source": [
    "## 15\n",
    "Write a Python program to convert a date of yyyy-mm-dd format to dd-mm-yyyy format.\n",
    "\n",
    "2026-01-02 should become 02-01-2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f81765d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original date: 2026-01-02\n",
      "Converted date: 02-01-2026\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_date_format(input_date):\n",
    "    # Parse the input date string\n",
    "    date_object = datetime.strptime(input_date, '%Y-%m-%d')\n",
    "\n",
    "    # Format the date in dd-mm-yyyy format\n",
    "    formatted_date = date_object.strftime('%d-%m-%Y')\n",
    "\n",
    "    return formatted_date\n",
    "\n",
    "# Example usage:\n",
    "input_date = \"2026-01-02\"\n",
    "converted_date = convert_date_format(input_date)\n",
    "\n",
    "print(f\"Original date: {input_date}\")\n",
    "print(f\"Converted date: {converted_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e6421",
   "metadata": {},
   "source": [
    "## 16\n",
    "Write a Python program to extract year, month and date from an url.\n",
    "\n",
    "`url = \"https://www.washingtonpost.com/news/football-insider/wp/2016/09/02/odell-beckhams-fame-rests-on-one-stupid-little-ball-josh-norman-tells-author/\"`\n",
    "\n",
    "output: [('2016', '09', '02')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7d0ca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.washingtonpost.com/news/football-insider/wp/2016/09/02/odell-beckhams-fame-rests-on-one-stupid-little-ball-josh-norman-tells-author/\n",
      "Extracted date: [('2016', '09', '02')]\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def extract_date_from_url(url):\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    # Extract the path from the URL\n",
    "    path = parsed_url.path\n",
    "\n",
    "    # Split the path into segments\n",
    "    path_segments = path.split('/')\n",
    "\n",
    "    # Look for the segment that represents the date\n",
    "    for i in range(len(path_segments) - 2):\n",
    "        if len(path_segments[i]) == 4 and len(path_segments[i + 1]) == 2 and len(path_segments[i + 2]) == 2:\n",
    "            # Extract year, month, and date\n",
    "            year, month, day = path_segments[i], path_segments[i + 1], path_segments[i + 2]\n",
    "            return [(year, month, day)]\n",
    "\n",
    "    return []\n",
    "\n",
    "# Example usage:\n",
    "url = \"https://www.washingtonpost.com/news/football-insider/wp/2016/09/02/odell-beckhams-fame-rests-on-one-stupid-little-ball-josh-norman-tells-author/\"\n",
    "output = extract_date_from_url(url)\n",
    "\n",
    "print(f\"URL: {url}\")\n",
    "print(f\"Extracted date: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27049f1f",
   "metadata": {},
   "source": [
    "## 17\n",
    "Write a Python program to separate and print the numbers of a given string.\n",
    "\n",
    "`String = \"Ten 10, Twenty 20, Thirty 30\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fac89176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string: Ten 10, Twenty 20, Thirty 30\n",
      "Extracted numbers: ['10', '20', '30']\n"
     ]
    }
   ],
   "source": [
    "def extract_numbers_from_string(input_string):\n",
    "    # Use regex to find all numbers in the string\n",
    "    numbers = re.findall(r'\\d+', input_string)\n",
    "\n",
    "    return numbers\n",
    "\n",
    "# Example usage:\n",
    "input_string = \"Ten 10, Twenty 20, Thirty 30\"\n",
    "numbers = extract_numbers_from_string(input_string)\n",
    "\n",
    "print(f\"Original string: {input_string}\")\n",
    "print(f\"Extracted numbers: {numbers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc0445",
   "metadata": {},
   "source": [
    "## 18\n",
    "Write a Python program to replace maximum 2 occurrences of space, comma, or dot with a colon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f18b787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string: I love Lady, she is the best. I am proud of you.\n",
      "Modified string: I:love:Lady, she is the best. I am proud of you.\n"
     ]
    }
   ],
   "source": [
    "def replace_delimiters_with_colon(input_string):\n",
    "    # Replace up to 2 occurrences of space, comma, or dot with a colon\n",
    "    replaced_string = re.sub(r'[ ,.]+', ':', input_string, count=2)\n",
    "\n",
    "    return replaced_string\n",
    "\n",
    "# Example usage:\n",
    "input_string = \"I love Lady, she is the best. I am proud of you.\"\n",
    "result = replace_delimiters_with_colon(input_string)\n",
    "\n",
    "print(f\"Original string: {input_string}\")\n",
    "print(f\"Modified string: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d6900",
   "metadata": {},
   "source": [
    "## 19\n",
    "Write a Python program to extract values between quotation marks of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8357601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: \"Python\", \"PHP\", \"Java\"\n",
      "Extracted values: ['Python', 'PHP', 'Java']\n"
     ]
    }
   ],
   "source": [
    "text1 = '\"Python\", \"PHP\", \"Java\"'\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_values_between_quotation_marks(input_text):\n",
    "    # Use regex to find all values between quotation marks\n",
    "    values = re.findall(r'\"(.*?)\"', input_text)\n",
    "\n",
    "    return values\n",
    "\n",
    "# Example usage:\n",
    "text1 = '\"Python\", \"PHP\", \"Java\"'\n",
    "extracted_values = extract_values_between_quotation_marks(text1)\n",
    "\n",
    "print(f\"Original text: {text1}\")\n",
    "print(f\"Extracted values: {extracted_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c95c7b",
   "metadata": {},
   "source": [
    "## 20\n",
    "Write a Python program to remove multiple spaces in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00993d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Python      Exercises\n",
      "Cleaned text: Python Exercises\n"
     ]
    }
   ],
   "source": [
    "text1 = 'Python      Exercises'\n",
    "\n",
    "def remove_multiple_spaces(input_text):\n",
    "    # Use regex to replace multiple spaces with a single space\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', input_text)\n",
    "\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "# Example usage:\n",
    "text1 = 'Python      Exercises'\n",
    "cleaned_text = remove_multiple_spaces(text1)\n",
    "\n",
    "print(f\"Original text: {text1}\")\n",
    "print(f\"Cleaned text: {cleaned_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff67c54",
   "metadata": {},
   "source": [
    "## 21\n",
    "Write a Python program to find all adverbs (ending on ly) and their positions in a given sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b6eb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Clearly, he has no excuse for such lying behavior.\n",
      "Adverbs and their positions: [('Clearly', 0)]\n"
     ]
    }
   ],
   "source": [
    "text = \"Clearly, he has no excuse for such lying behavior.\"\n",
    "\n",
    "def find_adverbs_positions(input_text):\n",
    "    # Use regex to find all adverbs ending in \"ly\"\n",
    "    adverbs_matches = re.finditer(r'\\b\\w+ly\\b', input_text)\n",
    "\n",
    "    # Extract adverbs and their positions\n",
    "    adverbs_positions = [(match.group(), match.start()) for match in adverbs_matches]\n",
    "\n",
    "    return adverbs_positions\n",
    "\n",
    "# Example usage:\n",
    "text = \"Clearly, he has no excuse for such lying behavior.\"\n",
    "adverbs_positions = find_adverbs_positions(text)\n",
    "\n",
    "print(f\"Original text: {text}\")\n",
    "print(f\"Adverbs and their positions: {adverbs_positions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0129b90",
   "metadata": {},
   "source": [
    "## 22\n",
    "Write a Python program to concatenate the consecutive numbers in a given string.\n",
    "\n",
    "Sample text:\n",
    "Enter at 1 20 Kearny Street. The security desk can direct you to floor 1 6. Please have your identification ready.\n",
    "\n",
    "Sample solution:\n",
    "Enter at 120 Kearny Street. The security desk can direct you to floor 16. Please have your identification ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18eae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Enter at 1 20 Kearny Street. The security desk can direct you to floor 1 6. Please have your identification ready.\n",
      "Modified text: Enter at 120 Kearny Street. The security desk can direct you to floor 16. Please have your identification ready.\n"
     ]
    }
   ],
   "source": [
    "txt = \"Enter at 1 20 Kearny Street. The security desk can direct you to floor 1 6. Please have your identification ready.\"\n",
    "\n",
    "def concatenate_consecutive_numbers(input_text):\n",
    "    # Use regex to find consecutive numbers and concatenate them\n",
    "    result_text = re.sub(r'(\\b\\d+)\\s+(\\d+\\b)', lambda match: match.group(1) + match.group(2), input_text)\n",
    "\n",
    "    return result_text\n",
    "\n",
    "# Example usage:\n",
    "txt = \"Enter at 1 20 Kearny Street. The security desk can direct you to floor 1 6. Please have your identification ready.\"\n",
    "result = concatenate_consecutive_numbers(txt)\n",
    "\n",
    "print(f\"Original text: {txt}\")\n",
    "print(f\"Modified text: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f04f6e",
   "metadata": {},
   "source": [
    "## 23\n",
    "Write a Python function that checks whether a word stars and ends with a vowel in a given string. Return true if a word matches the condition; otherwise, return false.\n",
    "\n",
    "Sample Data:\n",
    "- (\"Red Orange White\") -> True\n",
    "- (\"Red White Black\") -> False\n",
    "- (\"abcd dkise eosksu\") -> True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ab1f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Orange White -> True\n",
      "Red White Black -> False\n",
      "abcd dkise eosksu -> True\n"
     ]
    }
   ],
   "source": [
    "def word_starts_and_ends_with_vowel(input_string):\n",
    "    # Split the string into words\n",
    "    words = input_string.split()\n",
    "\n",
    "    # Check each word\n",
    "    for word in words:\n",
    "        # Check if the word starts and ends with a vowel\n",
    "        if word and word[0].lower() in 'aeiou' and word[-1].lower() in 'aeiou':\n",
    "            return True\n",
    "\n",
    "    # No matching word found\n",
    "    return False\n",
    "\n",
    "# Example usage:\n",
    "sample_data1 = \"Red Orange White\"\n",
    "sample_data2 = \"Red White Black\"\n",
    "sample_data3 = \"abcd dkise eosksu\"\n",
    "\n",
    "result1 = word_starts_and_ends_with_vowel(sample_data1)\n",
    "result2 = word_starts_and_ends_with_vowel(sample_data2)\n",
    "result3 = word_starts_and_ends_with_vowel(sample_data3)\n",
    "\n",
    "print(f\"{sample_data1} -> {result1}\")\n",
    "print(f\"{sample_data2} -> {result2}\")\n",
    "print(f\"{sample_data3} -> {result3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ee561",
   "metadata": {},
   "source": [
    "## 24\n",
    "Write a Python program to separate and print the numbers and their position of a given string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b441a6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: The following example creates 50 an ArrayList with a capacity of 50 elements. Four elements are then added to the ArrayList and the ArrayList is trimmed accordingly.\n",
      "Numbers and their positions: [('50', 30), ('50', 65)]\n"
     ]
    }
   ],
   "source": [
    "text = \"The following example creates 50 an ArrayList with a capacity of 50 elements. Four elements are then added to the ArrayList and the ArrayList is trimmed accordingly.\"\n",
    "\n",
    "def extract_numbers_and_positions(input_text):\n",
    "    # Use regex to find all numbers and their positions\n",
    "    matches = re.finditer(r'\\b\\d+\\b', input_text)\n",
    "\n",
    "    # Extract numbers and their positions\n",
    "    numbers_positions = [(match.group(), match.start()) for match in matches]\n",
    "\n",
    "    return numbers_positions\n",
    "\n",
    "# Example usage:\n",
    "text = \"The following example creates 50 an ArrayList with a capacity of 50 elements. Four elements are then added to the ArrayList and the ArrayList is trimmed accordingly.\"\n",
    "\n",
    "result = extract_numbers_and_positions(text)\n",
    "\n",
    "print(f\"Original text: {text}\")\n",
    "print(f\"Numbers and their positions: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d69bf0",
   "metadata": {},
   "source": [
    "## 25\n",
    "The given input strings contains some text followed by - followed by a number. Replace that number with its log value using math.log()\n",
    "\n",
    "- `s1 = 'first-3.14'`\n",
    "- `s2 = 'next-123'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87bd504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string 1: first-3.14\n",
      "Modified string 1: first-1.144222799920162\n",
      "Original string 2: next-123\n",
      "Modified string 2: next-4.812184355372417\n"
     ]
    }
   ],
   "source": [
    "s1 = 'first-3.14'\n",
    "s2 = 'next-123'\n",
    "\n",
    "def replace_number_with_log(input_string):\n",
    "    # Use regex to find the number after the hyphen\n",
    "    match = re.search(r'-(\\d+(\\.\\d+)?)', input_string)\n",
    "\n",
    "    if match:\n",
    "        # Extract the number\n",
    "        number_str = match.group(1)\n",
    "        number = float(number_str)\n",
    "\n",
    "        # Replace the number with its log value\n",
    "        log_value = math.log(number)\n",
    "        result_string = re.sub(r'-\\d+(\\.\\d+)?', f'-{log_value}', input_string)\n",
    "\n",
    "        return result_string\n",
    "\n",
    "    return input_string  # Return the original string if no match is found\n",
    "\n",
    "# Example usage:\n",
    "s1 = 'first-3.14'\n",
    "s2 = 'next-123'\n",
    "\n",
    "result1 = replace_number_with_log(s1)\n",
    "result2 = replace_number_with_log(s2)\n",
    "\n",
    "print(f\"Original string 1: {s1}\")\n",
    "print(f\"Modified string 1: {result1}\")\n",
    "\n",
    "print(f\"Original string 2: {s2}\")\n",
    "print(f\"Modified string 2: {result2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75876c93",
   "metadata": {},
   "source": [
    "## 26\n",
    "Extract all words between ( and ) from the given input string as a list. Assume that the input will not contain any broken parentheses.\n",
    "\n",
    "Text:\n",
    "`ip = 'another (way) to reuse (portion) matched (by) capture groups'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53412a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input string: another (way) to reuse (portion) matched (by) capture groups\n",
      "Words between parentheses: ['way', 'portion', 'by']\n"
     ]
    }
   ],
   "source": [
    "ip = 'another (way) to reuse (portion) matched (by) capture groups'\n",
    "\n",
    "def extract_words_between_parentheses(input_string):\n",
    "    # Use regex to find all words between parentheses\n",
    "    matches = re.findall(r'\\((.*?)\\)', input_string)\n",
    "\n",
    "    return matches\n",
    "\n",
    "# Example usage:\n",
    "ip = 'another (way) to reuse (portion) matched (by) capture groups'\n",
    "result = extract_words_between_parentheses(ip)\n",
    "\n",
    "print(f\"Input string: {ip}\")\n",
    "print(f\"Words between parentheses: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc9b2c",
   "metadata": {},
   "source": [
    "## 27\n",
    "Add [] around words starting with s and containing e and t in any order.\n",
    "\n",
    "text:\n",
    "`ip = 'sequoia subtle exhibit asset sets2 tests si_te'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "916ba408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input string: sequoia subtle exhibit asset sets2 tests si_te\n",
      "Modified string: sequoia subtle exhibit asset [sets2] tests si_te\n"
     ]
    }
   ],
   "source": [
    "ip = 'sequoia subtle exhibit asset sets2 tests si_te'\n",
    "\n",
    "def add_brackets_around_words(input_string):\n",
    "    # Use regex to add [] around words starting with 's' and containing 'e' and 't'\n",
    "    result_string = re.sub(r'\\bs[^ ]*e[^ ]*t[^ ]*\\b', lambda match: '[' + match.group() + ']', input_string)\n",
    "\n",
    "    return result_string\n",
    "\n",
    "# Example usage:\n",
    "ip = 'sequoia subtle exhibit asset sets2 tests si_te'\n",
    "result = add_brackets_around_words(ip)\n",
    "\n",
    "print(f\"Input string: {ip}\")\n",
    "print(f\"Modified string: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
